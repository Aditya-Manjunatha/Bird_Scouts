{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9713555,"sourceType":"datasetVersion","datasetId":5941976},{"sourceId":163653,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":139197,"modelId":161826}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:20:37.274810Z","iopub.execute_input":"2024-11-11T13:20:37.275217Z","iopub.status.idle":"2024-11-11T13:20:54.100939Z","shell.execute_reply.started":"2024-11-11T13:20:37.275173Z","shell.execute_reply":"2024-11-11T13:20:54.099777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torchaudio\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split, Subset\nfrom torchvision import models, transforms\nfrom torchvision.models import EfficientNet_B0_Weights\nfrom sklearn.model_selection import train_test_split\nimport torch.multiprocessing as mp\nfrom collections import Counter\nfrom sklearn.utils import resample\nfrom warmup_scheduler import GradualWarmupScheduler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:20:54.103184Z","iopub.execute_input":"2024-11-11T13:20:54.103518Z","iopub.status.idle":"2024-11-11T13:21:00.306606Z","shell.execute_reply.started":"2024-11-11T13:20:54.103481Z","shell.execute_reply":"2024-11-11T13:21:00.305582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if PyTorch is using the GPU\nprint(\"Is CUDA available? \", torch.cuda.is_available())\nprint(\"Device name: \", torch.cuda.get_device_name(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.307940Z","iopub.execute_input":"2024-11-11T13:21:00.308432Z","iopub.status.idle":"2024-11-11T13:21:00.370647Z","shell.execute_reply.started":"2024-11-11T13:21:00.308396Z","shell.execute_reply":"2024-11-11T13:21:00.369699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.372688Z","iopub.execute_input":"2024-11-11T13:21:00.373026Z","iopub.status.idle":"2024-11-11T13:21:00.377941Z","shell.execute_reply.started":"2024-11-11T13:21:00.372992Z","shell.execute_reply":"2024-11-11T13:21:00.376989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"directory_path = '/kaggle/working/new_directory'\n# Create the directory\nos.makedirs(directory_path, exist_ok=True)\nprint(f\"Directory '{directory_path}' has been created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.379208Z","iopub.execute_input":"2024-11-11T13:21:00.379518Z","iopub.status.idle":"2024-11-11T13:21:00.387937Z","shell.execute_reply.started":"2024-11-11T13:21:00.379477Z","shell.execute_reply":"2024-11-11T13:21:00.386986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/birds-audio-and-behavior-dataset/audio_metadata.csv'\ndf = pd.read_csv(csv_file_path)\npaths = []\n\n# Loop through each row in the DataFrame\nfor index, row in df.iterrows():\n    # Concatenate the path with the id\n    path = \"/kaggle/input/birds-audio-and-behavior-dataset/Audio_files/\" + str(row[\"id\"]) + '.mp3'\n    # Append the path to the list\n    paths.append(path)\n\n# Assign the list of paths to the 'path' column\ndf[\"path\"] = paths\ndf[\"sound_label\"] = df[\"sound_label\"].apply(lambda x: x.split(';')[0].strip())\ndf.drop(['common_name', 'scientific_name'], axis=1, inplace=True)\n\n# directory_path = 'output'\n# os.makedirs(directory_path, exist_ok=True)\nnew_csv_file_path = '/kaggle/working/new_directory/audio_metadata.csv'\ndf.to_csv(new_csv_file_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.389095Z","iopub.execute_input":"2024-11-11T13:21:00.389430Z","iopub.status.idle":"2024-11-11T13:21:00.817130Z","shell.execute_reply.started":"2024-11-11T13:21:00.389398Z","shell.execute_reply":"2024-11-11T13:21:00.816109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_spec_params = {\n    \"sample_rate\": 44100,\n    \"n_mels\": 256,\n    \"f_min\": 20,\n    \"f_max\": 22050,\n    \"n_fft\": 2048,\n    \"hop_length\": 512,\n    \"normalized\": True,\n    \"center\" : True,\n    \"pad_mode\" : \"constant\",\n    \"norm\" : \"slaney\",\n    \"onesided\" : True,\n    \"mel_scale\" : \"slaney\"\n}\n\nlabel_mapping = {\n    'Call': 0,\n    'Song': 1,\n    'Dawn song': 2,\n    'Non-vocal': 3,\n    'Duet': 4,\n    'Flight song': 5,\n    'Flight call': 6\n}\n\n# augmentations = [\n#     lambda x: torchaudio.transforms.PitchShift(sample_rate=16000, n_steps=2).to(device)(x.to(device)),\n#     lambda x: x.to(device) + torch.randn_like(x.to(device)) * 0.01,  # Add noise\n#     lambda x: torch.roll(x.to(device), shifts=int(0.1 * x.size(1)), dims=1),  # Time shift\n#     lambda x: torchaudio.transforms.Vol(3).to(device)(x.to(device))  # Change volume\n# ]\n\ntop_db = 80\ntrain_period = 10\nval_period = 10\nremove_duration = 12 * mel_spec_params[\"sample_rate\"]\ntrain_duration = train_period * mel_spec_params[\"sample_rate\"]\nval_duration = val_period * mel_spec_params[\"sample_rate\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.818416Z","iopub.execute_input":"2024-11-11T13:21:00.818810Z","iopub.status.idle":"2024-11-11T13:21:00.826321Z","shell.execute_reply.started":"2024-11-11T13:21:00.818713Z","shell.execute_reply":"2024-11-11T13:21:00.825341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_melspec(X, eps=1e-6):\n    X = X.to(device)  # Move tensor to GPU\n    mean = X.mean((1, 2), keepdim=True)\n    stdout = X.std((1, 2), keepdim=True)\n    Xstd = (X - mean) / (stdout + eps)\n\n    norm_min, norm_max = (\n        Xstd.min(-1)[0].min(-1)[0],\n        Xstd.max(-1)[0].max(-1)[0],\n    )\n    fix_ind = (norm_max - norm_min) > eps * torch.ones_like((norm_max - norm_min)).to(device)\n    V = torch.zeros_like(Xstd).to(device)\n    if fix_ind.sum():\n        V_fix = Xstd[fix_ind]\n        norm_max_fix = norm_max[fix_ind, None, None]\n        norm_min_fix = norm_min[fix_ind, None, None]\n        V_fix = torch.max(\n            torch.min(V_fix, norm_max_fix),\n            norm_min_fix,\n        )\n        V_fix = (V_fix - norm_min_fix) / (norm_max_fix - norm_min_fix)\n        V[fix_ind] = V_fix\n    return V\n\ndef read_wav(path):\n    wav, org_sr = torchaudio.load(path, normalize=True)\n    wav = torchaudio.functional.resample(wav, orig_freq=org_sr, new_freq=mel_spec_params[\"sample_rate\"])\n    wav = wav.to(device)  # Move tensor to GPU\n    return wav\n\ndef crop_start_wav(wav, remove_duration, use_duration):\n    wav = wav.to(device)  # Ensure tensor is on GPU\n    if wav.size(-1) > remove_duration + use_duration:\n        wav = wav[:, remove_duration:remove_duration + use_duration]\n    return wav","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.827907Z","iopub.execute_input":"2024-11-11T13:21:00.828316Z","iopub.status.idle":"2024-11-11T13:21:00.843699Z","shell.execute_reply.started":"2024-11-11T13:21:00.828263Z","shell.execute_reply":"2024-11-11T13:21:00.842615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class BirdCallDataset(Dataset):\n    def __init__(self, csv_file, transform=None, augmentations=None):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.augmentations = augmentations\n        self.mel_transform = torchaudio.transforms.MelSpectrogram(**mel_spec_params).to(device)\n        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype='power', top_db=top_db).to(device)\n\n    def __len__(self):\n        return len(self.data)\n\n    def prepare_spec(self, path):\n        wav = read_wav(path).to(device)\n        wav = crop_start_wav(wav, remove_duration, train_duration).to(device)  # Ensure wav is on GPU\n        \n        # Apply augmentations\n        if self.augmentations:\n            for aug in self.augmentations:\n                wav = aug(wav).to(device)\n\n        mel_spectrogram = normalize_melspec(self.db_transform(self.mel_transform(wav))).to(device)\n        mel_spectrogram = mel_spectrogram * 255\n\n        # Ensure the tensor has 3 channels\n        if mel_spectrogram.size(0) == 1:\n            mel_spectrogram = mel_spectrogram.repeat(3, 1, 1)\n        elif mel_spectrogram.size(0) == 2:\n            mel_spectrogram = torch.cat([mel_spectrogram, mel_spectrogram[0:1, :, :]], dim=0)\n        elif mel_spectrogram.size(0) != 3:\n            raise RuntimeError(f\"Unexpected tensor size: {mel_spectrogram.size()}\")\n\n        mel_spectrogram = mel_spectrogram.permute(1, 2, 0).cpu().detach().numpy()  # Move back to CPU for numpy\n        return mel_spectrogram\n    \n    def __getitem__(self, idx):\n        audio_path = self.data.iloc[idx, 2]\n        label = self.data.iloc[idx, 1]\n\n        spec = self.prepare_spec(audio_path)\n    \n        if self.transform is not None:\n            res = self.transform(spec)\n            spec = res\n        else:\n            spec = spec\n        \n        return spec, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.844921Z","iopub.execute_input":"2024-11-11T13:21:00.845274Z","iopub.status.idle":"2024-11-11T13:21:00.859328Z","shell.execute_reply.started":"2024-11-11T13:21:00.845241Z","shell.execute_reply":"2024-11-11T13:21:00.858488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the model class\nclass BirdCallClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(BirdCallClassifier, self).__init__()\n        weights = EfficientNet_B0_Weights.DEFAULT\n        self.efficientnet = models.efficientnet_b0(weights=weights)\n        self.efficientnet.classifier[1] = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(self.efficientnet.classifier[1].in_features, num_classes)\n        )\n    def forward(self, x):\n        x = x.to(device)  # Ensure input is on GPU\n        x = self.efficientnet(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.862351Z","iopub.execute_input":"2024-11-11T13:21:00.862696Z","iopub.status.idle":"2024-11-11T13:21:00.875352Z","shell.execute_reply.started":"2024-11-11T13:21:00.862662Z","shell.execute_reply":"2024-11-11T13:21:00.874471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.876398Z","iopub.execute_input":"2024-11-11T13:21:00.876694Z","iopub.status.idle":"2024-11-11T13:21:00.890496Z","shell.execute_reply.started":"2024-11-11T13:21:00.876663Z","shell.execute_reply":"2024-11-11T13:21:00.889522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, scheduler=None):\n    model = model.to(device)\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            num_batches = len(dataloaders[phase])\n            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                numerical_labels = torch.tensor([label_mapping[label] for label in labels], dtype=torch.long).to(device)\n                \n                # Print the progress\n                print(f\"Processing batch {batch_idx + 1}/{num_batches} in {phase} phase\")\n\n                # sample_rate = 44100  # Assuming a sample rate of 32kHz\n                # min_duration = 22 * sample_rate  # Minimum number of samples for 22 seconds\n                # if any(input.size(-1) < min_duration for input in inputs):\n                #     print(f\"Skipping batch {batch_idx + 1}/{num_batches} in {phase} phase due to short spectrogram\")\n                #     continue\n\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, numerical_labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == numerical_labels)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n        # Step the scheduler if provided\n        if scheduler and phase == 'train':\n            scheduler.step(epoch_loss)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:23:26.791892Z","iopub.execute_input":"2024-11-11T13:23:26.792848Z","iopub.status.idle":"2024-11-11T13:23:26.804908Z","shell.execute_reply.started":"2024-11-11T13:23:26.792807Z","shell.execute_reply":"2024-11-11T13:23:26.803645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define validation function\ndef validate_model(model, dataloader, criterion):\n    model = model.to(device)\n    \n    model.eval()  # Set model to evaluation mode\n    running_loss = 0.0\n    running_corrects = 0\n\n    with torch.no_grad():\n        num_batches = len(dataloader)\n        for batch_idx, (inputs, labels) in enumerate(dataloader):\n            inputs = inputs.to(device)\n            numerical_labels = torch.tensor([label_mapping[label] for label in labels], dtype=torch.long).to(device)\n            \n            # Print the progress\n            print(f\"Processing batch {batch_idx + 1}/{num_batches}\")\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, numerical_labels)\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == numerical_labels)\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n\n    print(f'Validation Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n    return epoch_loss, epoch_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:23:30.453512Z","iopub.execute_input":"2024-11-11T13:23:30.453912Z","iopub.status.idle":"2024-11-11T13:23:30.462794Z","shell.execute_reply.started":"2024-11-11T13:23:30.453874Z","shell.execute_reply":"2024-11-11T13:23:30.461784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model parameters\ndef save_model(model, path):\n    torch.save(model.state_dict(), path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.921498Z","iopub.execute_input":"2024-11-11T13:21:00.921833Z","iopub.status.idle":"2024-11-11T13:21:00.934399Z","shell.execute_reply.started":"2024-11-11T13:21:00.921800Z","shell.execute_reply":"2024-11-11T13:21:00.933531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def balance_dataset(dataset):\n    # Get the labels\n    labels = dataset.data['sound_label']\n    label_counts = Counter(labels)\n    min_count = min(label_counts.values())\n\n    # Create a balanced dataset\n    balanced_indices = []\n    for label in label_counts:\n        label_indices = [i for i, l in enumerate(labels) if l == label]\n        balanced_indices.extend(resample(label_indices, replace=False, n_samples=min_count, random_state=42))\n\n    return Subset(dataset, balanced_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:21:00.935610Z","iopub.execute_input":"2024-11-11T13:21:00.935951Z","iopub.status.idle":"2024-11-11T13:21:00.946104Z","shell.execute_reply.started":"2024-11-11T13:21:00.935899Z","shell.execute_reply":"2024-11-11T13:21:00.945249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    csv_file = '/kaggle/working/new_directory/audio_metadata.csv'\n    num_classes = 7  # Adjust based on your dataset\n    batch_size = 64\n    num_epochs = 8  # Increase the number of epochs\n    learning_rate = 0.001\n\n    dataset = BirdCallDataset(csv_file, transform=transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        # transforms.RandomHorizontalFlip(),  # Added augmentation\n        # transforms.RandomCrop(224, padding=4),  # Added augmentation\n        transforms.ToTensor(),\n    ]), augmentations=None)\n\n    # Balance the dataset\n    labels = dataset.data['sound_label']\n\n    train_indices, temp_indices, train_labels, temp_labels = train_test_split(\n        range(len(labels)), labels, stratify=labels, test_size=0.4, random_state=42)\n\n    val_indices, test_indices, val_labels, test_labels = train_test_split(\n        temp_indices, temp_labels, stratify=temp_labels, test_size=0.5, random_state=42)\n\n    train_dataset = Subset(dataset, train_indices)\n    val_dataset = Subset(dataset, val_indices)\n    test_dataset = Subset(dataset, test_indices)\n\n    dataloaders = {\n        'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n        'val': DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0),\n        'test': DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n    }\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    model = BirdCallClassifier(num_classes=num_classes).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    after_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')  # Added learning rate scheduler\n    scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=1, total_epoch=5, after_scheduler=after_scheduler)  # Added warmup scheduler\n\n    model = train_model(model, dataloaders, criterion, optimizer, num_epochs=num_epochs, scheduler=scheduler)\n    save_model(model, '/kaggle/working/new_directory/bird_call_classifier.pth')\n\n    # Validate the model on the test set\n    print(\"Testing the model on the test set:\")\n    validate_model(model, dataloaders['test'], criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T13:23:35.241954Z","iopub.execute_input":"2024-11-11T13:23:35.242347Z","iopub.status.idle":"2024-11-11T13:24:19.160116Z","shell.execute_reply.started":"2024-11-11T13:23:35.242310Z","shell.execute_reply":"2024-11-11T13:24:19.158523Z"}},"outputs":[],"execution_count":null}]}